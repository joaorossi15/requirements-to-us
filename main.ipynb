{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMRpjyUnyQ1a2PHa2f9Zw9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaorossi15/requirements-to-us/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install git\n",
        "! git clone https://github.com/joaorossi15/requirements-to-us.git\n",
        "! pip install langchain_community\n",
        "! pip install chromadb\n",
        "! pip install pypdf\n",
        "! pip install importmonkey\n",
        "! pip install optimum\n",
        "! pip install auto-gptq\n",
        "! pip install peft"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z3-nVfP9WZPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importmonkey import add_path\n",
        "add_path(\"/content/requirements-to-us/\")\n",
        "import flow\n",
        "from rag.rag import generate_store"
      ],
      "metadata": {
        "id": "n-Im13JeR5lk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate vector database using the domain specific knowledge documents"
      ],
      "metadata": {
        "id": "_FyZWGP-TEHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_store(\"./requirements-to-us/rag-data/\", \"./requirements-to-us/chroma/\")"
      ],
      "metadata": {
        "id": "TUZGqLiBTue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create langchain pipeline to use the vector database and the model to generate the best response possible"
      ],
      "metadata": {
        "id": "btynC8HTTTaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WF3jJueNCTzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = flow.model_rag(persist_path=\"./requirements-to-us/chroma/\")"
      ],
      "metadata": {
        "id": "7SsM6LbCKJID",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"The user needs the AI to not take decisions without his consent\"\n",
        "\n",
        "c = chain.invoke(query)"
      ],
      "metadata": {
        "id": "ZgPJLNJ4-WkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response generated"
      ],
      "metadata": {
        "id": "-V-R5YGHTh6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(c['text'].split('[/INST]')[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRtazqcWESHo",
        "outputId": "34cdd2f3-49fa-4b23-a83f-844837956df4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    **Ethical User Story:** As a user, I want to be informed and have control over the decisions made by the AI, ensuring my reasonable expectations and consent are respected at all times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Documents used for context"
      ],
      "metadata": {
        "id": "iZEkq8G_Tjwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c['context']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBgyNZ_7385z",
        "outputId": "2fe8dc80-36de-4f49-c835-9bc4c85f92f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 13, 'source': 'requirements-to-us/rag-data/ryan.pdf'}, page_content='reasonable expectations and consent of the individuals but must also be used for legitimate\\npurposes (Future Advocacy, 2019).\\n4.7.4 Choice. AI should protect users’ power to decide about decisions in their lives\\n(Floridi et al., 2018). AI should not “compromise human freedom and autonomy by\\nillegitimately and surreptitiously reducing options for and knowledge of citizens” (European\\nGroup on Ethics in Science and New Technologies, 2018,p .1 7 ) .'),\n",
              " Document(metadata={'page': 1, 'source': 'requirements-to-us/rag-data/ryan.pdf'}, page_content='AI. [1] We believe that the paper provides the most comprehensive account of ethical\\nrequirements in AI guidelines currently available, which is of interest not only to the\\nresearch and policy community engaged in the topic but also to the user communities that\\nrequire guidance when developing or deploying AI systems. It must be made clear here that\\nwe are not providing prescriptive recommendations, but rather, are mapping the\\nprescriptive recommendations found in these guidelines.'),\n",
              " Document(metadata={'page': 10, 'source': 'requirements-to-us/rag-data/ryan.pdf'}, page_content='how they function and their potential impacts (Algo.Rules, 2019), and security precautions\\nmust be well documented (Public Voice 2018). AI organisations may receive advice from\\ntrained legal professionals, ethicists working in the area and policy analysts. If no consensus\\ncan be agreed upon, development of the AI“should not proceed in that form” (High-Level\\nExpert Group on AI, 2019, p. 20). AI systems need to allow for human interruption, or their'),\n",
              " Document(metadata={'page': 13, 'source': 'requirements-to-us/rag-data/ryan.pdf'}, page_content='Group on Ethics in Science and New Technologies, 2018,p .1 7 ) .\\n4.7.5 Self-determination. There needs to be a balance between decision-making power\\nthat is freely given by the user to the autonomous systems and when this option is taken\\naway or undermined by the system (Floridi et al.,2 0 1 8). AI organisations should not\\nmanipulate individual’s self-determination, particularly those who may be vulnerable to\\nabuse (Rathenau Institute, 2017,p .2 6 ) .')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaeILo_iBnty"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}